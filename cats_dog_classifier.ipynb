{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Input, GlobalAvgPool2D,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Directory: D:\\Machine learning\\Cats vs  Dog classifier\\Dataset\\test_set\n",
      "Test Directory: D:\\Machine learning\\Cats vs  Dog classifier\\Dataset\\training_set\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.abspath(r\"D:\\Machine learning\\Cats vs  Dog classifier\\Dataset\\test_set\")\n",
    "test_dir = os.path.abspath(r\"D:\\Machine learning\\Cats vs  Dog classifier\\Dataset\\training_set\")\n",
    "\n",
    "print(\"Train Directory:\", train_dir)\n",
    "print(\"Test Directory:\", test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  rotation_range=40,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,)\n",
    "test_datagen = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  rotation_range=40,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1992 images belonging to 2 classes.\n",
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator =  train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size = 20,\n",
    "    target_size  = (255,255),\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "test_generator  = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size = 20,\n",
    "    target_size = (255,255),\n",
    "    class_mode = \"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(input_shape=(255,255,3), include_top=False , weights= \"imagenet\")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAvgPool2D(),\n",
    "    Dense(64,activation = \"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"],\n",
    "    optimizer = \"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 8, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                81984     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,340,033\n",
      "Trainable params: 82,049\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 97s - loss: 0.1882 - accuracy: 0.9287 - 97s/epoch - 973ms/step\n",
      "Epoch 2/5\n",
      "100/100 - 59s - loss: 0.1066 - accuracy: 0.9639 - 59s/epoch - 593ms/step\n",
      "Epoch 3/5\n",
      "100/100 - 56s - loss: 0.0931 - accuracy: 0.9629 - 56s/epoch - 555ms/step\n",
      "Epoch 4/5\n",
      "100/100 - 56s - loss: 0.0982 - accuracy: 0.9603 - 56s/epoch - 564ms/step\n",
      "Epoch 5/5\n",
      "100/100 - 55s - loss: 0.0844 - accuracy: 0.9684 - 55s/epoch - 546ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2303a481430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,epochs = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 361s 896ms/step - loss: 0.0835 - accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08345016837120056, 0.9670206308364868]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
